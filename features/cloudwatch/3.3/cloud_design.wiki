= Overview =

This design covers our implementation of AWS Cloud Watch. 

== Out of Scope ==
Implementation of items related to features that we do not support are out of scope. These features are:

* Placement groups
* Spot Instances
* SNS
* VPC
* VPC
* SNS
* DynamoDB
* Billing
* ElastiCache
* ElasticMapReduce
* RDS
* SQS
* StorageGateway

== Feature Dependencies ==
* EC2 - Data collection for system-defined metrics.
* EBS - Data collection for EBS disk system-defined metrics.
* AS - Support execution of autoscaling policies from alarm triggers, and collection of system metrics.
* ELB - Data collection for ELB system metrics.

== Related Features ==
This feature relates to the following features in this release:
* EC2
* ELB
* AS
* ELB

= Design =

=== Entity Model ===

Database: eucalyptus_cloudwatch 

Tables: 

system_metric_data_0, system_metric_data_1, ... system_metric_data_f 

custom_metric_data_0, custom_metric_data_1, ... custom_metric_data_f

32 tables with identical columns (metric_data is the template table) (used for PutMetricData/GetMetricStatistics)
list_metrics (metrics for ListMetrics)

CRUD design -- 

PutMetricData and GetMetricStatistics

Create : An aggregation queue will be used to aggregate whatever data points that can be combined within the window.
For each data point, a table will be selected based on a hash of the dimensions (key:value) and metric type.  
All tables have the following columns: account_id, user_id, namespace, metric_name, units, metric_type (system or custom), timestamp, dimension_hash, sample_sum, sample_max, sample_min, sample_size, dimensions (dim1name, dim1value, ... dim10name, dim10value) 

System metrics may be "folded", that is not all dimensions need to be selected during a search.  To accomodate this, rows for each combination of dimensions for a given input will be created and placed into the table with the appropriate hash.  Current system metrics appear to have at most 4 dimensions which would result in at most 16 rows.  10 dimensions would result in 2^10 = 1024 rows.

(Note, timestamp format :  http://en.wikipedia.org/wiki/ISO_8601 : Timestamps to be truncated to the previous minute)

Read : Search will be done on equality on metric_name, metric_type, namespace, and units.  Dimensions will be searched against the dimension hash.  Custom metrics require all dimensions match, system metrics require only a subset.

Update : Not required

Delete - removes rows in which have a time stamp that is equals (current system time - (current time + two weeks))

ListMetrics

Create : The metric info (without metric value), will be persisted persisted with the following column definitions :

Per row entry - account, uuid, MetricName, NameSpace, timestamp (create and update), dimension columns (dim_x_name, dim_x_value for x between 1 and 10)

Read: Searches can be based on metric name, namespace, or a dimension list (dimension subset match is allowed).  
Result will include the entire dimension list entered with the metric

Update: Only the update timestamp of the list_metrics row will be updated

Delete - remove rows that have an update time stamp that is equals (current system time - (current time + two weeks)).

Uniqueness_Constraints: Only the combination of account_id, metric_name, namespace, and dimension key/values (in order) need to be unique.

=== Service Impact ===

CLC -> Consume general jvm resource the cloud controller

DB -> additional jdbc connections 

Alarms -> additional duty cycle in which will spawn more threads

Must be HA compliant 

=== Put Metric Workflow ===

[[File:put-metric-data-workflow.png]] 

=== Put Metric Workflow Diagram Definitions === 

* PutMetricData -> user created request 

* Cloud Watch Service -> Eucalyptus implementation of the Cloud Watch Service

* Raw Data Queue -> FIFO queue

* Aggregation -> Function to process an aggregation of one minute window of raw data to be inserted into the database.  Every put_metric_data call also updates the list_metrics table

* Cleaner -> House keeping process to delete metric data from the database with a 2 week window  

* Data Points Rows / Metric Data Table -> A table is selected based on dimension hash and metric type, processed information.

=== List Metrics Workflow ===

[[File:list-metrics-workflow.png]] 

=== List Metrics Workflow Diagram Definitions === 

* ListMetrics -> user created request 

* Cloud Watch Service -> Eucalyptus implementation of the Cloud Watch Service

* Cleaner -> House keeping process to delete metric data from the database with a 2 week window  

* list_metrics -> Processed information

* PutMetricData -> Previous workflow also populates list_metrics table

=== Get Metric Workflow ===

[[File:get-metric-statistics-workflow.png]] 

=== Get Metric Workflow Diagram Definitions === 

* GetMetricStatistics -> user created request 

* Cloud Watch Service -> Eucalyptus implementation of the Cloud Watch Service

* Aggregation -> Function to convert one or more raw data rows into an aggregated statistic based on the period selected

* Data Points Rows / Metric Data Table -> A table is selected based on dimension hash and metric type, processed information.

=== Database Purge ===

Global period data deletion after 2 weeks.

=== Discovery ===
Filters should be discovered, whether individually, per type or per API.

= Upgrade =
No upgrade impact noted.

= Packaging =
No specific packaging requirements.

= Documentation =
*Need feedback from the docs team

= Security =
Each operation must adhere with the Eucalyptus implementation of the IAM-compatible identity management system.

= Testing =
Testing should cover SOAP and Query APIs 

= References =
AWS Cloud Watch : http://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/Welcome.html
JIRA https://eucalyptus.atlassian.net/browse/EUCA-4307

